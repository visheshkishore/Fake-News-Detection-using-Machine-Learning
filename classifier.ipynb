{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news = pd.read_csv('train.csv')\n",
    "test_news = pd.read_csv('test.csv')\n",
    "valid_news = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset size:\n",
      "(10240, 2)\n",
      "                                           Statement  Label\n",
      "0  Says the Annies List political group supports ...  False\n",
      "1  When did the decline of coal start? It started...   True\n",
      "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
      "3  Health care reform legislation is likely to ma...  False\n",
      "4  The economic turnaround started at the end of ...   True\n",
      "5  The Chicago Bears have had more starting quart...   True\n",
      "6  Jim Dunnam has not lived in the district he re...  False\n",
      "7  I'm the only person on this stage who has work...   True\n",
      "8  However, it took $19.5 million in Oregon Lotte...   True\n",
      "9  Says GOP primary opponents Glenn Grothman and ...   True\n",
      "Testing dataset size:\n",
      "(2551, 2)\n",
      "                                           Statement  Label\n",
      "0  Building a wall on the U.S.-Mexico border will...   True\n",
      "1  Wisconsin is on pace to double the number of l...  False\n",
      "2  Says John McCain has done nothing to help the ...  False\n",
      "3  Suzanne Bonamici supports a plan that will cut...   True\n",
      "4  When asked by a reporter whether hes at the ce...  False\n",
      "5  Over the past five years the federal governmen...   True\n",
      "6  Says that Tennessee law requires that schools ...   True\n",
      "7  Says Vice President Joe Biden \"admits that the...  False\n",
      "8  Donald Trump is against marriage equality. He ...   True\n",
      "9  We know that more than half of Hillary Clinton...  False\n",
      "validation dataset size:\n",
      "(2571, 2)\n",
      "                                           Statement  Label\n",
      "0  We have less Americans working now than in the...  FALSE\n",
      "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
      "2  Says Having organizations parading as being so...  FALSE\n",
      "3     Says nearly half of Oregons children are poor.   TRUE\n",
      "4  On attacks by Republicans that various program...   TRUE\n",
      "5  Says when armed civilians stop mass shootings ...  FALSE\n",
      "6  Says Tennessee is providing millions of dollar...   TRUE\n",
      "7  The health care reform plan would set limits s...  FALSE\n",
      "8  Says Donald Trump started his career back in 1...   TRUE\n",
      "9  Bill White has a long history of trying to lim...   TRUE\n"
     ]
    }
   ],
   "source": [
    "print(\"training dataset size:\")\n",
    "print(train_news.shape)\n",
    "print(train_news.head(10))\n",
    "\n",
    "print(\"Testing dataset size:\")\n",
    "print(test_news.shape)\n",
    "print(test_news.head(10))\n",
    "    \n",
    "print(\"validation dataset size:\")\n",
    "print(valid_news.shape)   \n",
    "print(valid_news.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When asked by a reporter whether hes at the center of a criminal scheme to violate campaign laws, Gov. Scott Walker nodded yes.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news['Statement'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Labels count in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc059b1ba90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='Label', data=train_news, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels count in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc055308970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='Label', data=test_news, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data qualitites...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Statement  10240 non-null  object\n",
      " 1   Label      10240 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 90.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking data qualitites...\")\n",
    "train_news.isnull().sum()\n",
    "train_news.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data qualities in testing set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2551 entries, 0 to 2550\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Statement  2551 non-null   object\n",
      " 1   Label      2551 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 22.5+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking data qualities in testing set:\")\n",
    "test_news.isnull().sum()\n",
    "test_news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming to reduce words to its word stems\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for token in tokens:\n",
    "        stemmed.append(stemmer.stem(token))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the data\n",
    "def process_data(data,exclude_stopword=True,stem=True):\n",
    "    tokens = [w.lower() for w in data]\n",
    "    tokens_stemmed = tokens\n",
    "    tokens_stemmed = stem_tokens(tokens, eng_stemmer)\n",
    "    tokens_stemmed = [w for w in tokens_stemmed if w not in stopwords ]\n",
    "    return tokens_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating unigram in nltk\n",
    "def create_unigram(words):\n",
    "    assert type(words) == list\n",
    "    return words\n",
    "\n",
    "#creating bigram in nltk\n",
    "def create_bigrams(words):\n",
    "    assert type(words) == list\n",
    "    skip = 0\n",
    "    join_str = \" \"\n",
    "    Len = len(words)\n",
    "    if Len > 1:\n",
    "        lst = []\n",
    "        for i in range(Len-1):\n",
    "            for k in range(1,skip+2):\n",
    "                if i+k < Len:\n",
    "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
    "    else:\n",
    "        #set it as unigram\n",
    "        lst = create_unigram(words)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bag of words using Count vectorizer and TF-IDF to convert unstructured data into set of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will start with simple bag of words technique using count vectorizer\n",
    "#creating feature vector - document term matrix\n",
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(train_news['Statement'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n",
      "  (0, 9676)\t1\n",
      "  (0, 10988)\t1\n",
      "  (0, 1044)\t1\n",
      "  (0, 6639)\t1\n",
      "  (0, 8376)\t1\n",
      "  (0, 5115)\t1\n",
      "  (0, 10709)\t1\n",
      "  (0, 11036)\t1\n",
      "  (0, 11296)\t1\n",
      "  (0, 615)\t1\n",
      "  (0, 7728)\t1\n",
      "  (0, 3278)\t1\n",
      "  (1, 10988)\t1\n",
      "  (1, 11934)\t2\n",
      "  (1, 3434)\t1\n",
      "  (1, 3185)\t1\n",
      "  (1, 7672)\t1\n",
      "  (1, 2475)\t1\n",
      "  (1, 10425)\t1\n",
      "  (1, 6052)\t1\n",
      "  (1, 10426)\t2\n",
      "  (1, 7418)\t1\n",
      "  (1, 4860)\t1\n",
      "  (1, 11138)\t1\n",
      "  (1, 7674)\t1\n",
      "  :\t:\n",
      "  (10239, 10988)\t1\n",
      "  (10239, 7672)\t2\n",
      "  (10239, 11110)\t2\n",
      "  (10239, 5267)\t1\n",
      "  (10239, 7828)\t1\n",
      "  (10239, 7824)\t1\n",
      "  (10239, 1159)\t1\n",
      "  (10239, 12151)\t2\n",
      "  (10239, 6327)\t1\n",
      "  (10239, 6603)\t1\n",
      "  (10239, 11013)\t1\n",
      "  (10239, 11004)\t1\n",
      "  (10239, 3309)\t1\n",
      "  (10239, 12158)\t1\n",
      "  (10239, 11660)\t2\n",
      "  (10239, 799)\t1\n",
      "  (10239, 2568)\t1\n",
      "  (10239, 11622)\t1\n",
      "  (10239, 2549)\t1\n",
      "  (10239, 10660)\t1\n",
      "  (10239, 8996)\t1\n",
      "  (10239, 10918)\t1\n",
      "  (10239, 3989)\t1\n",
      "  (10239, 10594)\t1\n",
      "  (10239, 6853)\t1\n"
     ]
    }
   ],
   "source": [
    "print(countV)\n",
    "print(train_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will use bag of words technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072128577028616"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building classifier using naive bayes \n",
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV', countV),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline.fit(train_news['Statement'], train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.591140729125833"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression classifier\n",
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',countV),\n",
    "        ('LogR_clf',LogisticRegression())\n",
    "        ])\n",
    "\n",
    "logR_pipeline.fit(train_news['Statement'], train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5723245785966288"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm classifier\n",
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',countV),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613092904743238"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stochastic gradient descent\n",
    "sgd_pipeline = Pipeline([\n",
    "        ('svm2CV',countV),\n",
    "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613092904743238"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest classifier\n",
    "random_forest = Pipeline([\n",
    "        ('rfCV',countV),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=100,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf = random_forest.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for train_ind, test_ind in k_fold.split(train_news):\n",
    "        train_text = train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = train_news.iloc[test_ind]['Statement']\n",
    "        test_y = train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(train_news)),\n",
    "    print('F1-Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "F1-Score: 0.66961153965076\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2118 2370]\n",
      " [1664 4088]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "F1-Score: 0.7025623649614049\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1177 3311]\n",
      " [ 844 4908]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(logR_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "F1-Score: 0.6104687487924283\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2260 2228]\n",
      " [2246 3506]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(svm_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.659933439952882\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1490 2998]\n",
      " [1442 4310]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far we have used bag of words technique to extract the features and passed those featuers into classifiers. We have also seen the f1 scores of these classifiers. Now lets enhance these features using term frequency weights with various n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using n-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938847510780086"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Using Naive-Bayes\n",
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb_ngram == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193649549196394"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression classifier\n",
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_ngram == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170129361034888"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear SVM classifier\n",
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm_ngram == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417483339866719"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sgd classifier\n",
    "sgd_pipeline_ngram = Pipeline([\n",
    "         ('sgd_tfidf',tfidf_ngram),\n",
    "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
    "         ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd_ngram == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025088200705606"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "random_forest_ngram = Pipeline([\n",
    "        ('rf_tfidf',tfidf_ngram),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_ngram == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "F1-Score: 0.7224053159841455\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[ 758 3730]\n",
      " [ 390 5362]]\n",
      "Total statements classified: 10240\n",
      "F1-Score: 0.7044355553757985\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1580 2908]\n",
      " [1043 4709]]\n",
      "Total statements classified: 10240\n",
      "F1-Score: 0.6790920142902143\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2016 2472]\n",
      " [1524 4228]]\n",
      "Total statements classified: 10240\n",
      "F1-Score: 0.7190643331130575\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[   5 4483]\n",
      " [   6 5746]]\n",
      "Total statements classified: 10240\n",
      "F1-Score: 0.6583368788755276\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1993 2495]\n",
      " [1705 4047]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline_ngram)\n",
    "build_confusion_matrix(logR_pipeline_ngram)\n",
    "build_confusion_matrix(svm_pipeline_ngram)\n",
    "build_confusion_matrix(sgd_pipeline_ngram)\n",
    "build_confusion_matrix(random_forest_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.19      0.30      1169\n",
      "        True       0.58      0.94      0.71      1382\n",
      "\n",
      "    accuracy                           0.59      2551\n",
      "   macro avg       0.65      0.56      0.51      2551\n",
      "weighted avg       0.64      0.59      0.52      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive-Bayes Classification Report\")\n",
    "print(classification_report(test_news['Label'], predicted_nb_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.39      0.49      1169\n",
      "        True       0.61      0.81      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Classification Report\")\n",
    "print(classification_report(test_news['Label'], predicted_LogR_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.47      0.53      1169\n",
      "        True       0.62      0.74      0.68      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.61      0.61      0.60      2551\n",
      "weighted avg       0.62      0.62      0.61      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classification Report\")\n",
    "print(classification_report(test_news['Label'], predicted_svm_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.46      0.52      1169\n",
      "        True       0.61      0.72      0.66      1382\n",
      "\n",
      "    accuracy                           0.60      2551\n",
      "   macro avg       0.60      0.59      0.59      2551\n",
      "weighted avg       0.60      0.60      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classification Report\")\n",
    "print(classification_report(test_news['Label'], predicted_rf_ngram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We can see that random forest and logistic regression are best performing in terms of precision and recall (take a look into false positive and true negative counts which appeares to be low compared to rest of the models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Grid Search CV to optimise best fit parameters for Logistic regression and Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV on random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.05791745, 1.94410877, 2.47894258, 2.41898675, 3.2570385 ,\n",
       "        3.03598804, 3.6386713 , 3.57822642, 4.12078052, 4.09138455,\n",
       "        1.90244536, 1.98958316, 2.66954861, 2.55533762, 3.13792133,\n",
       "        3.08940535, 3.86097908, 3.79714036, 4.47562609, 4.71137695,\n",
       "        2.19359903, 2.13679881, 2.63193178, 2.53701353, 3.43978577,\n",
       "        3.24730372, 3.96850977, 3.82996416, 4.4389679 , 4.42904477,\n",
       "        2.2643662 , 2.07664795, 2.77371664, 2.81122794, 3.46569057,\n",
       "        3.36376495, 4.12080417, 4.11133976, 4.88107572, 5.1925787 ,\n",
       "        2.18099952, 2.13722062, 3.06852369, 2.91428499, 3.59014993,\n",
       "        3.75721073, 4.18661566, 4.14944611, 4.84700422, 4.99697213,\n",
       "        2.3089788 , 2.12737741, 3.07097144, 3.01708899, 3.84008365,\n",
       "        3.75498099, 4.62137299, 4.80059695, 5.21201115, 5.34382601,\n",
       "        2.40601473, 2.32536445, 3.21112356, 3.29042358, 4.46569257,\n",
       "        4.25964193, 5.94388795, 5.13165693, 5.95458031, 5.72306232,\n",
       "        2.543436  , 2.61354084, 3.63459477, 3.52051291, 4.43787704,\n",
       "        4.64451008, 5.59544768, 5.10991669, 5.70329289, 5.89425926,\n",
       "        2.5671041 , 2.42454085, 3.46091323, 3.47377133, 4.46125784,\n",
       "        4.48574066, 5.30034661, 5.34273429, 6.07121272, 6.91677814,\n",
       "        2.95996804, 2.67639656, 3.86104383, 3.74416289, 5.06271777,\n",
       "        5.11155586, 5.86558375, 5.71516399, 6.55292721, 6.80103912,\n",
       "        2.79501057, 2.69236417, 3.92168026, 4.0808919 , 5.23623257,\n",
       "        5.55865984, 6.51426854, 6.17541242, 7.09107304, 7.30741954,\n",
       "        2.97297797, 2.84005671, 4.20234108, 4.25438662, 5.61457791,\n",
       "        5.4074327 , 6.85488157, 6.61211653, 7.36676054, 7.70287728,\n",
       "        3.08183346, 3.0314538 , 4.35106592, 4.48419662, 5.84384336,\n",
       "        5.82957606, 6.93255467, 6.84677258, 8.37400661, 8.21280141,\n",
       "        3.20474949, 2.97448168, 4.62915545, 4.77259407, 6.21752453,\n",
       "        6.10288043, 7.4329493 , 7.25977826, 8.34978085, 8.98384304,\n",
       "        3.36543193, 3.0714972 , 4.87467561, 4.86635213, 6.6549222 ,\n",
       "        6.44673696, 7.74254632, 7.63134313, 8.73396406, 8.08463836]),\n",
       " 'std_fit_time': array([0.0682666 , 0.15872444, 0.04155896, 0.03240142, 0.19168696,\n",
       "        0.07641423, 0.06378281, 0.04662548, 0.05604676, 0.11006068,\n",
       "        0.15953679, 0.11625701, 0.09652838, 0.06910566, 0.05295377,\n",
       "        0.0956642 , 0.04738992, 0.06078442, 0.16541312, 0.21317847,\n",
       "        0.19256344, 0.13213319, 0.05794462, 0.05072625, 0.1444314 ,\n",
       "        0.038865  , 0.09640824, 0.08409701, 0.072775  , 0.14133174,\n",
       "        0.05628444, 0.07200185, 0.04131806, 0.07124476, 0.08833867,\n",
       "        0.07093732, 0.10498766, 0.09596097, 0.3152032 , 0.20938529,\n",
       "        0.11353325, 0.08768599, 0.04878126, 0.09049032, 0.06579881,\n",
       "        0.05705676, 0.10764635, 0.19323454, 0.1874747 , 0.34199704,\n",
       "        0.14666994, 0.09320982, 0.09637177, 0.10757373, 0.07289136,\n",
       "        0.08668614, 0.21014002, 0.36384777, 0.06754213, 0.13678918,\n",
       "        0.10846186, 0.06661845, 0.0605244 , 0.20195638, 0.27959626,\n",
       "        0.2455423 , 0.34868444, 0.22877287, 0.23462736, 0.2109719 ,\n",
       "        0.32514537, 0.11724263, 0.02441076, 0.05817789, 0.22983071,\n",
       "        0.1735746 , 0.24948   , 0.0569527 , 0.15553116, 0.36800788,\n",
       "        0.15974554, 0.13220671, 0.29207799, 0.05471667, 0.11718798,\n",
       "        0.09380513, 0.10466827, 0.09937708, 0.14631341, 0.83743945,\n",
       "        0.26472115, 0.12764937, 0.10706472, 0.17981787, 0.11677981,\n",
       "        0.06052535, 0.15569069, 0.12832267, 0.05410385, 0.55072339,\n",
       "        0.35472734, 0.18836803, 0.15019173, 0.08420612, 0.26359725,\n",
       "        0.19883707, 0.12570683, 0.0684598 , 0.196553  , 0.28721889,\n",
       "        0.24156811, 0.09190045, 0.32124686, 0.26462666, 0.1467573 ,\n",
       "        0.28225224, 0.29330882, 0.16306157, 0.08632974, 0.48017525,\n",
       "        0.33233615, 0.12227438, 0.21883901, 0.10512774, 0.12265575,\n",
       "        0.18674441, 0.12841484, 0.09237251, 0.20328745, 0.39987302,\n",
       "        0.22563036, 0.16325251, 0.25907085, 0.09003592, 0.1803128 ,\n",
       "        0.18392921, 0.09559006, 0.06817218, 0.37563414, 0.33440732,\n",
       "        0.15843636, 0.12098922, 0.2365055 , 0.13022696, 0.25933368,\n",
       "        0.21180273, 0.12031268, 0.17952033, 0.16305563, 0.73610182]),\n",
       " 'mean_score_time': array([0.33547597, 0.27935028, 0.34380913, 0.33600783, 0.40006661,\n",
       "        0.42807837, 0.45983686, 0.45902734, 0.53859148, 0.53780499,\n",
       "        0.24353018, 0.28635736, 0.34778056, 0.34156289, 0.42943754,\n",
       "        0.39002042, 0.41676197, 0.38476787, 0.48767428, 0.48422623,\n",
       "        0.25747523, 0.23211441, 0.33835826, 0.35168142, 0.42710032,\n",
       "        0.40548263, 0.49764247, 0.47635651, 0.5452178 , 0.49957175,\n",
       "        0.23584576, 0.24093208, 0.32829418, 0.31178966, 0.38464804,\n",
       "        0.39859676, 0.42290626, 0.39495482, 0.50776072, 0.47690921,\n",
       "        0.2377759 , 0.23085823, 0.31418738, 0.33418679, 0.39751844,\n",
       "        0.38495317, 0.47240901, 0.45634866, 0.50218301, 0.4684257 ,\n",
       "        0.25720854, 0.24646068, 0.31286225, 0.31249056, 0.37704005,\n",
       "        0.38029642, 0.46510248, 0.43836288, 0.4793817 , 0.48167505,\n",
       "        0.25513306, 0.23885341, 0.34352102, 0.37715163, 0.38121562,\n",
       "        0.37357469, 0.45826144, 0.41942434, 0.55508094, 0.46613345,\n",
       "        0.27207408, 0.25175781, 0.34933305, 0.36889801, 0.38830314,\n",
       "        0.42680936, 0.42102742, 0.41250162, 0.50774736, 0.48042827,\n",
       "        0.24335303, 0.24969802, 0.34465342, 0.33035235, 0.3813972 ,\n",
       "        0.37649817, 0.40738463, 0.40347981, 0.46944084, 0.62853107,\n",
       "        0.24813037, 0.23853698, 0.36580954, 0.30418348, 0.36426716,\n",
       "        0.35559359, 0.45879354, 0.41487093, 0.48117599, 0.47312241,\n",
       "        0.23302531, 0.25521846, 0.31316161, 0.30914679, 0.3945981 ,\n",
       "        0.36093087, 0.43010736, 0.40688601, 0.48359151, 0.4512836 ,\n",
       "        0.23665051, 0.24003611, 0.30942497, 0.31108689, 0.38397617,\n",
       "        0.36589651, 0.45824838, 0.40812082, 0.46111293, 0.47086282,\n",
       "        0.23597875, 0.24045701, 0.31909599, 0.3104188 , 0.38964701,\n",
       "        0.35987639, 0.45143132, 0.4635469 , 0.49123707, 0.47186556,\n",
       "        0.23944602, 0.24739389, 0.30973291, 0.31812091, 0.38058286,\n",
       "        0.36659341, 0.45002627, 0.41453495, 0.50405731, 0.5429256 ,\n",
       "        0.24969292, 0.24741597, 0.31435633, 0.30102868, 0.36432123,\n",
       "        0.38220797, 0.45078487, 0.41996245, 0.50900574, 0.40672565]),\n",
       " 'std_score_time': array([0.03354772, 0.04113711, 0.02382694, 0.04567335, 0.04837621,\n",
       "        0.06985549, 0.03872427, 0.06522196, 0.03210386, 0.08408962,\n",
       "        0.02602557, 0.03747452, 0.04511843, 0.03151088, 0.05468517,\n",
       "        0.03622671, 0.04093093, 0.02583308, 0.04047078, 0.05808194,\n",
       "        0.02353038, 0.02249566, 0.01769285, 0.04400058, 0.04738281,\n",
       "        0.02360054, 0.04416534, 0.06208585, 0.05353777, 0.03369649,\n",
       "        0.00402618, 0.00987037, 0.00916124, 0.01756902, 0.03621318,\n",
       "        0.0722923 , 0.03052198, 0.01805105, 0.05082301, 0.05675911,\n",
       "        0.00529502, 0.00623554, 0.02601149, 0.03795414, 0.05154259,\n",
       "        0.04891491, 0.04708831, 0.05736335, 0.06401145, 0.02705052,\n",
       "        0.02199627, 0.01185783, 0.01190439, 0.00832942, 0.02171302,\n",
       "        0.02152788, 0.05100901, 0.05652051, 0.03814341, 0.06889225,\n",
       "        0.01575649, 0.01741286, 0.02673437, 0.03546131, 0.04459033,\n",
       "        0.0338588 , 0.02486836, 0.03349128, 0.11220766, 0.02434891,\n",
       "        0.0142988 , 0.00983357, 0.02089696, 0.06634253, 0.02554866,\n",
       "        0.01540682, 0.0337299 , 0.02389092, 0.06728151, 0.08072048,\n",
       "        0.01294243, 0.01711542, 0.01660803, 0.03197994, 0.02566191,\n",
       "        0.02280939, 0.02004723, 0.03334309, 0.00668412, 0.08804749,\n",
       "        0.02010141, 0.00915852, 0.06211383, 0.00967602, 0.02417516,\n",
       "        0.03120346, 0.06770298, 0.0229528 , 0.03322718, 0.01923955,\n",
       "        0.00845235, 0.01083619, 0.01507475, 0.02626897, 0.03984361,\n",
       "        0.0238587 , 0.01819568, 0.02868321, 0.01512222, 0.0322502 ,\n",
       "        0.01007308, 0.00572804, 0.00906652, 0.01450644, 0.01687338,\n",
       "        0.01790911, 0.06002245, 0.03077479, 0.03235998, 0.05298503,\n",
       "        0.01006646, 0.00844667, 0.01131528, 0.0135881 , 0.02907908,\n",
       "        0.0188282 , 0.02151195, 0.10652754, 0.02083791, 0.04148588,\n",
       "        0.0183746 , 0.01121488, 0.01121061, 0.02013584, 0.02029528,\n",
       "        0.02082743, 0.02873076, 0.03071844, 0.06540525, 0.06162963,\n",
       "        0.01329697, 0.00909705, 0.0121206 , 0.00870119, 0.0144539 ,\n",
       "        0.03443087, 0.06219187, 0.03325622, 0.03225506, 0.08686087]),\n",
       " 'param_rf_clf__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.561 , 0.561 , 0.561 ,\n",
       "        0.5605, 0.561 , 0.5615, 0.561 , 0.561 , 0.561 , 0.5605, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.5615, 0.5605, 0.561 , 0.561 , 0.5615, 0.561 ,\n",
       "        0.5605, 0.561 , 0.5615, 0.5605, 0.5615, 0.5615, 0.5605, 0.561 ,\n",
       "        0.561 , 0.5605, 0.5605, 0.562 , 0.5615, 0.5615, 0.5615, 0.562 ,\n",
       "        0.5615, 0.5615, 0.5615, 0.561 , 0.5595, 0.56  , 0.562 , 0.5615,\n",
       "        0.5635, 0.5615, 0.562 , 0.5615, 0.561 , 0.561 , 0.5625, 0.56  ,\n",
       "        0.563 , 0.5615, 0.563 , 0.562 , 0.5625, 0.563 , 0.5615, 0.5615,\n",
       "        0.5595, 0.5595, 0.562 , 0.563 , 0.564 , 0.5625, 0.5625, 0.561 ,\n",
       "        0.562 , 0.562 , 0.562 , 0.561 , 0.562 , 0.5615, 0.564 , 0.563 ,\n",
       "        0.5625, 0.561 , 0.562 , 0.562 , 0.563 , 0.564 , 0.5645, 0.5635,\n",
       "        0.5635, 0.562 , 0.5645, 0.5635, 0.5625, 0.5615]),\n",
       " 'split1_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.562 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.562 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.562 , 0.5615, 0.562 , 0.562 , 0.561 ,\n",
       "        0.561 , 0.5615, 0.561 , 0.561 , 0.561 , 0.5625, 0.562 , 0.563 ,\n",
       "        0.5645, 0.5615, 0.562 , 0.562 , 0.562 , 0.561 , 0.5635, 0.564 ,\n",
       "        0.5625, 0.563 , 0.5635, 0.5625, 0.563 , 0.5615, 0.561 , 0.562 ,\n",
       "        0.5635, 0.5645, 0.562 , 0.5615, 0.564 , 0.564 , 0.5625, 0.562 ,\n",
       "        0.564 , 0.5625, 0.5655, 0.565 , 0.564 , 0.564 , 0.566 , 0.5635,\n",
       "        0.563 , 0.5635, 0.5635, 0.5635, 0.567 , 0.5695, 0.5655, 0.5665,\n",
       "        0.5645, 0.5665, 0.563 , 0.565 , 0.564 , 0.563 ]),\n",
       " 'split2_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.56  , 0.561 , 0.5615, 0.561 ,\n",
       "        0.5615, 0.5615, 0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.5605,\n",
       "        0.562 , 0.5615, 0.5605, 0.561 , 0.5615, 0.561 , 0.5615, 0.561 ,\n",
       "        0.5595, 0.561 , 0.564 , 0.561 , 0.565 , 0.5625, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5625, 0.562 , 0.5655, 0.5625, 0.5605, 0.563 ,\n",
       "        0.5625, 0.563 , 0.563 , 0.562 , 0.566 , 0.5645, 0.5645, 0.5615,\n",
       "        0.5625, 0.5635, 0.5635, 0.5615, 0.562 , 0.563 , 0.565 , 0.5655,\n",
       "        0.56  , 0.5615, 0.562 , 0.5635, 0.5605, 0.563 , 0.5625, 0.5625,\n",
       "        0.5665, 0.5685, 0.564 , 0.565 , 0.564 , 0.5655, 0.5625, 0.559 ,\n",
       "        0.566 , 0.561 , 0.5695, 0.567 , 0.568 , 0.5635, 0.5625, 0.5635,\n",
       "        0.5615, 0.5615, 0.56  , 0.563 , 0.5705, 0.5695, 0.5665, 0.565 ,\n",
       "        0.565 , 0.5645, 0.563 , 0.564 , 0.5635, 0.5625]),\n",
       " 'split3_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.5615,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.5615, 0.562 , 0.5615, 0.5615, 0.5615, 0.561 , 0.562 , 0.561 ,\n",
       "        0.562 , 0.561 , 0.5615, 0.5615, 0.561 , 0.5625, 0.561 , 0.562 ,\n",
       "        0.561 , 0.562 , 0.562 , 0.561 , 0.562 , 0.5625, 0.5605, 0.562 ,\n",
       "        0.562 , 0.562 , 0.5625, 0.5625, 0.563 , 0.562 , 0.566 , 0.564 ,\n",
       "        0.5635, 0.563 , 0.5645, 0.564 , 0.563 , 0.562 , 0.563 , 0.5625,\n",
       "        0.5665, 0.565 , 0.565 , 0.563 , 0.5635, 0.564 , 0.5625, 0.5625,\n",
       "        0.5635, 0.5625, 0.5645, 0.567 , 0.5655, 0.5635, 0.565 , 0.564 ,\n",
       "        0.563 , 0.562 , 0.564 , 0.563 , 0.5695, 0.569 , 0.565 , 0.564 ,\n",
       "        0.563 , 0.5645, 0.5645, 0.5635, 0.562 , 0.563 ]),\n",
       " 'split4_test_score': array([0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.562 , 0.5615,\n",
       "        0.562 , 0.562 , 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.562 , 0.5615, 0.5615, 0.562 , 0.5615, 0.5615, 0.5615,\n",
       "        0.563 , 0.5615, 0.5625, 0.5625, 0.5625, 0.5635, 0.563 , 0.5625,\n",
       "        0.5615, 0.5615, 0.563 , 0.5615, 0.5625, 0.563 , 0.564 , 0.562 ,\n",
       "        0.5635, 0.562 , 0.5635, 0.562 , 0.562 , 0.5625, 0.563 , 0.566 ,\n",
       "        0.566 , 0.5635, 0.5655, 0.563 , 0.5645, 0.5635, 0.5625, 0.5635,\n",
       "        0.5635, 0.564 , 0.564 , 0.5645, 0.566 , 0.564 , 0.563 , 0.564 ,\n",
       "        0.563 , 0.5625, 0.566 , 0.5645, 0.566 , 0.566 , 0.567 , 0.5665,\n",
       "        0.565 , 0.5645, 0.565 , 0.5635, 0.567 , 0.5655, 0.568 , 0.5655,\n",
       "        0.5675, 0.5655, 0.566 , 0.565 , 0.565 , 0.5635]),\n",
       " 'mean_test_score': array([0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.561 , 0.5611, 0.5612, 0.5611,\n",
       "        0.561 , 0.5611, 0.5612, 0.5611, 0.561 , 0.5611, 0.5611, 0.5612,\n",
       "        0.5612, 0.5612, 0.5611, 0.5611, 0.5612, 0.5611, 0.5613, 0.561 ,\n",
       "        0.5614, 0.5613, 0.5611, 0.561 , 0.5612, 0.5611, 0.5613, 0.5611,\n",
       "        0.561 , 0.5614, 0.5619, 0.5611, 0.5622, 0.5615, 0.5614, 0.5612,\n",
       "        0.5617, 0.5611, 0.5616, 0.562 , 0.5624, 0.5624, 0.5616, 0.5621,\n",
       "        0.5615, 0.5619, 0.5621, 0.5613, 0.5622, 0.5625, 0.5626, 0.562 ,\n",
       "        0.5632, 0.5621, 0.5627, 0.5619, 0.562 , 0.5619, 0.564 , 0.5639,\n",
       "        0.563 , 0.5625, 0.5637, 0.563 , 0.5627, 0.5626, 0.5621, 0.5624,\n",
       "        0.5639, 0.5643, 0.5634, 0.5634, 0.5643, 0.564 , 0.5626, 0.5617,\n",
       "        0.5637, 0.5621, 0.5655, 0.5649, 0.5651, 0.5637, 0.5649, 0.5641,\n",
       "        0.563 , 0.5625, 0.5629, 0.563 , 0.5674, 0.5675, 0.5659, 0.5649,\n",
       "        0.5647, 0.5646, 0.5642, 0.5642, 0.5634, 0.5627]),\n",
       " 'std_test_score': array([0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.00031623, 0.0002    , 0.00024495,\n",
       "        0.0002    , 0.00031623, 0.0002    , 0.00024495, 0.0002    ,\n",
       "        0.00054772, 0.0002    , 0.00037417, 0.00024495, 0.00024495,\n",
       "        0.00024495, 0.0002    , 0.0002    , 0.00024495, 0.0002    ,\n",
       "        0.0006    , 0.00031623, 0.0004899 , 0.0004    , 0.00037417,\n",
       "        0.00031623, 0.00024495, 0.0002    , 0.00024495, 0.0002    ,\n",
       "        0.00089443, 0.0004899 , 0.00106771, 0.00037417, 0.00143527,\n",
       "        0.00054772, 0.0004899 , 0.00024495, 0.00074833, 0.00037417,\n",
       "        0.0008    , 0.00031623, 0.00162481, 0.00066332, 0.00086023,\n",
       "        0.00066332, 0.00054772, 0.0005831 , 0.0008    , 0.0004    ,\n",
       "        0.0021587 , 0.00144914, 0.00146287, 0.00054772, 0.00087178,\n",
       "        0.00073485, 0.00067823, 0.00037417, 0.00063246, 0.0008    ,\n",
       "        0.00130384, 0.00210713, 0.00192354, 0.00083666, 0.0012083 ,\n",
       "        0.00070711, 0.00128841, 0.00073485, 0.00073485, 0.00066332,\n",
       "        0.00257682, 0.00287402, 0.0012    , 0.00124097, 0.00087178,\n",
       "        0.00094868, 0.0002    , 0.00166132, 0.00132665, 0.0005831 ,\n",
       "        0.00242899, 0.0022    , 0.00200998, 0.00143527, 0.00156205,\n",
       "        0.00124097, 0.00114018, 0.00130384, 0.00174356, 0.00054772,\n",
       "        0.00259615, 0.00230217, 0.00124097, 0.00106771, 0.00156844,\n",
       "        0.00149666, 0.0011225 , 0.00067823, 0.00106771, 0.00067823]),\n",
       " 'rank_test_score': array([ 79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "         79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,  79,\n",
       "        145,  79,  72,  79, 145,  79,  72,  79, 145,  79,  79,  71,  72,\n",
       "         72,  79,  79,  72,  79,  67, 145,  64,  70,  79, 145,  72,  79,\n",
       "         68,  79, 145,  64,  54,  79,  44,  62,  66,  72,  59,  79,  60,\n",
       "         51,  41,  41,  61,  46,  62,  54,  46,  68,  44,  38,  35,  51,\n",
       "         26,  46,  32,  56,  51,  56,  17,  18,  28,  40,  20,  27,  34,\n",
       "         35,  46,  41,  18,  11,  23,  24,  12,  16,  35,  58,  22,  46,\n",
       "          4,   6,   5,  21,   6,  15,  28,  38,  31,  28,   2,   1,   3,\n",
       "          6,   9,  10,  13,  13,  24,  32], dtype=int32)}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest classifier parameters\n",
    "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'rf_tfidf__use_idf': (True, False),\n",
    "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "    accuracy                           0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running random forest with best fit parameters\n",
    "random_forest_final = Pipeline([\n",
    "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "        ])\n",
    "    \n",
    "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_final == test_news['Label'])\n",
    "print(classification_report(test_news['Label'], predicted_rf_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV on Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.76091952, 0.60784583, 0.68526177, 0.59933453, 2.70275064,\n",
       "        2.99390879, 2.68246036, 2.88668075, 4.04407511, 4.76716256,\n",
       "        3.392627  , 4.43623347, 4.44313183, 5.4668292 , 4.46057744,\n",
       "        5.46071744, 5.39540162, 6.6831512 , 5.75138631, 6.07942777]),\n",
       " 'std_fit_time': array([0.0468712 , 0.02037098, 0.01789055, 0.02513488, 0.0809045 ,\n",
       "        0.07600858, 0.21086912, 0.15415291, 0.67291193, 0.13158532,\n",
       "        0.18778975, 0.10799173, 0.12823854, 0.36351509, 0.24208702,\n",
       "        0.25126863, 0.51389872, 0.36663017, 0.19156945, 0.62948591]),\n",
       " 'mean_score_time': array([0.09294715, 0.08580074, 0.08765912, 0.0861228 , 0.19040136,\n",
       "        0.16311221, 0.18887038, 0.16006775, 0.20040655, 0.18680367,\n",
       "        0.22354903, 0.17905269, 0.2215548 , 0.22373414, 0.24284439,\n",
       "        0.22110138, 0.26464324, 0.26055217, 0.26652555, 0.19655066]),\n",
       " 'std_score_time': array([0.00603275, 0.00309436, 0.00455389, 0.00401503, 0.04175516,\n",
       "        0.02713858, 0.02040714, 0.0251129 , 0.02834775, 0.02153618,\n",
       "        0.03432275, 0.02500336, 0.02237562, 0.02390382, 0.03939118,\n",
       "        0.02800391, 0.03057998, 0.01669959, 0.03307048, 0.05717343]),\n",
       " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.6135, 0.617 , 0.6125, 0.617 , 0.619 , 0.617 , 0.6175, 0.617 ,\n",
       "        0.6205, 0.6175, 0.621 , 0.6175, 0.6175, 0.6155, 0.6175, 0.6155,\n",
       "        0.614 , 0.615 , 0.6115, 0.615 ]),\n",
       " 'split1_test_score': array([0.618 , 0.6205, 0.6185, 0.6205, 0.6245, 0.623 , 0.625 , 0.623 ,\n",
       "        0.6245, 0.6165, 0.624 , 0.6165, 0.623 , 0.613 , 0.6205, 0.613 ,\n",
       "        0.622 , 0.6135, 0.619 , 0.6135]),\n",
       " 'split2_test_score': array([0.5945, 0.603 , 0.596 , 0.603 , 0.6025, 0.6015, 0.605 , 0.6015,\n",
       "        0.604 , 0.6045, 0.608 , 0.6045, 0.609 , 0.603 , 0.607 , 0.603 ,\n",
       "        0.6065, 0.601 , 0.609 , 0.601 ]),\n",
       " 'split3_test_score': array([0.599 , 0.608 , 0.5995, 0.608 , 0.6105, 0.605 , 0.6105, 0.605 ,\n",
       "        0.6125, 0.606 , 0.615 , 0.606 , 0.617 , 0.611 , 0.616 , 0.611 ,\n",
       "        0.621 , 0.6115, 0.618 , 0.6115]),\n",
       " 'split4_test_score': array([0.598 , 0.6045, 0.601 , 0.6045, 0.6145, 0.606 , 0.612 , 0.606 ,\n",
       "        0.613 , 0.607 , 0.613 , 0.607 , 0.616 , 0.606 , 0.6185, 0.606 ,\n",
       "        0.6165, 0.6055, 0.618 , 0.6055]),\n",
       " 'mean_test_score': array([0.6046, 0.6106, 0.6055, 0.6106, 0.6142, 0.6105, 0.614 , 0.6105,\n",
       "        0.6149, 0.6103, 0.6162, 0.6103, 0.6165, 0.6097, 0.6159, 0.6097,\n",
       "        0.616 , 0.6093, 0.6151, 0.6093]),\n",
       " 'std_test_score': array([0.00933488, 0.0069383 , 0.00853815, 0.0069383 , 0.00748064,\n",
       "        0.00812404, 0.0067897 , 0.00812404, 0.00709507, 0.00553715,\n",
       "        0.00570614, 0.00553715, 0.00447214, 0.00457821, 0.00468402,\n",
       "        0.00457821, 0.00557674, 0.00525928, 0.00405463, 0.00525928]),\n",
       " 'rank_test_score': array([20,  9, 19,  9,  7, 11,  8, 11,  6, 13,  2, 13,  1, 15,  4, 15,  3,\n",
       "        17,  5, 17], dtype=int32)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression parameters\n",
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.38      0.48      1169\n",
      "        True       0.61      0.82      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running logistic regression with best fit parameters\n",
    "logR_pipeline_final = Pipeline([\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == test_news['Label'])\n",
    "#accuracy = 0.62\n",
    "print(classification_report(test_news['Label'], predicted_LogR_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the best model i.e Logistic regression in final_model.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(pipeline,title):\n",
    "    size = 100\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = train_news[\"Statement\"]\n",
    "    y = train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(logR_pipeline_ngram, \"LogisticRegression Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the news text you want to verify: When asked by a reporter whether hes at the center of a criminal scheme to violate campaign laws, Gov. Scott Walker nodded yes\n",
      "You entered: When asked by a reporter whether hes at the center of a criminal scheme to violate campaign laws, Gov. Scott Walker nodded yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var = input(\"Please enter the news text you want to verify: \")\n",
    "print(\"You entered: \" + str(var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to run for prediction\n",
    "def detecting_fake_news(var):    \n",
    "#retrieving the best model for prediction call\n",
    "    load_model = pickle.load(open('final_model.sav', 'rb'))\n",
    "    prediction = load_model.predict([var])\n",
    "    prob = load_model.predict_proba([var])\n",
    "\n",
    "    return (print(\"The given statement is \",prediction[0]),\n",
    "        print(\"The truth probability score is \",prob[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given statement is  False\n",
      "The truth probability score is  0.2790938656560584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detecting_fake_news(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
